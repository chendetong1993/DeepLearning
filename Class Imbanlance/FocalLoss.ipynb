{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal Loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Focal Loss面试题:\n",
    "1. 为什么是Focal Loss\n",
    "    Focal loss主要是为了解决one-stage目标检测中正负样本比例严重失衡的问题。该损失函数降低了大量简单负样本在训练中所占的权重，也可理解为一种困难样本挖掘. Focal loss是在交叉熵损失函数基础上进行的修改.\n",
    "  \n",
    "2. 为什么Focal Loss效果好\n",
    "    只添加alpha虽然可以平衡正负样本的重要性，但是无法解决简单与困难样本的问题. gamma调节简单样本权重降低的速率，当gamma为0时即为交叉熵损失函数，当gamma增加时，调整因子的影响也在增加。实验发现gamma为2是最优。\n",
    "    \n",
    "3. Focal Loss如何进行反向传播"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss On Binary Classification\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss on Binary Classification\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss On Softmax Classification\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss On Softmax Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "2.2.4-tf\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal Loss on Binary Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = np.where(y_train > 0, 1.0, 0.0), np.where(y_test > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    layers.Reshape([28, 28, 1], input_shape=(28,28), name='repshape'),\n",
    "    layers.Conv2D(32, 3, 1, name='conv1'),\n",
    "    layers.BatchNormalization(name='bn1'),\n",
    "    layers.Activation(activation='relu', name='relu1'),\n",
    "    layers.Conv2D(64, 3, 1, name='conv2'),\n",
    "    layers.BatchNormalization(name='bn2'),\n",
    "    layers.Activation(activation='relu', name='relu2'),\n",
    "    layers.Conv2D(128, 3, 1, name='conv3'),\n",
    "    layers.BatchNormalization(name='bn3'),\n",
    "    layers.Activation(activation='relu', name='relu3'),\n",
    "    layers.GlobalAveragePooling2D(name='gap'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "        \n",
    "class binary_accuracy(metrics.Metric):\n",
    "    def __init__(self, name='binary_accuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.acc_numerator = self.add_weight(name=\"acc_numerator\", initializer='zeros')\n",
    "        self.acc_denominator = self.add_weight(name=\"acc_denominator\", initializer='zeros')\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred >= 0.5, tf.int32)\n",
    "        y_true = tf.reshape(tf.cast(y_true, tf.int32), [-1])\n",
    "        self.acc_numerator.assign_add(tf.reduce_sum(tf.cast(y_pred == y_true, tf.float32)))\n",
    "        self.acc_denominator.assign_add(tf.cast(tf.shape(y_pred)[0], tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.acc_numerator / self.acc_denominator\n",
    "        \n",
    "    def reset_states(self):\n",
    "        self.acc_numerator.assign(0.)\n",
    "        self.acc_denominator.assign(0.)\n",
    "        \n",
    "        \n",
    "def log_loss(y_actual, y_pred):\n",
    "    log = lambda x : tf.math.log(tf.math.maximum(x, 1e-7)) # prevent log(0) causing nan\n",
    "    loss = - (y_actual) * log(y_pred) - (1 - y_actual) * log(1 - y_pred)\n",
    "    return loss\n",
    "\n",
    "def focal_loss(y_actual, y_pred):\n",
    "    log = lambda x : tf.math.log(tf.math.maximum(x, 1e-7)) # prevent log(0) causing nan\n",
    "    alpha, gamma = 0.25, 2\n",
    "    loss = - alpha * y_actual * tf.math.pow(1 - y_pred, gamma) * log(y_pred) \\\n",
    "            - (1 - alpha) * (1 - y_actual) * tf.math.pow(y_pred, gamma) * log(1 - y_pred)\n",
    "    return loss\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-4), loss=log_loss, metrics=[binary_accuracy()])\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs = 5)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-4), loss=focal_loss, metrics=[binary_accuracy()])\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal Loss on Multiclass  Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = y_train.astype(np.float32), y_test.astype(np.float32)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "#y_train, y_test = np.where(y_train > 0, 1.0, 0.0), np.where(y_test > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.0813 - multiclass_accuracy: 0.9886\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-11522ee8c31c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfocal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmulticlass_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m                       total_epochs=1)\n\u001b[0m\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Program Files\\Programming Solution\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    layers.Reshape([28, 28, 1], input_shape=(28,28), name='repshape'),\n",
    "    layers.Conv2D(16, 3, 1, name='conv1'),\n",
    "    layers.BatchNormalization(name='bn1'),\n",
    "    layers.Activation(activation='relu', name='relu1'),\n",
    "    layers.Conv2D(32, 3, 1, name='conv2'),\n",
    "    layers.BatchNormalization(name='bn2'),\n",
    "    layers.Activation(activation='relu', name='relu2'),\n",
    "    layers.Conv2D(64, 3, 1, name='conv3'),\n",
    "    layers.BatchNormalization(name='bn3'),\n",
    "    layers.Activation(activation='relu', name='relu3'),\n",
    "    layers.Flatten(name='flat4'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "class multiclass_accuracy(metrics.Metric):\n",
    "    def __init__(self, name='multiclass_accuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.acc_numerator = self.add_weight(name=\"acc_numerator\", initializer='zeros')\n",
    "        self.acc_denominator = self.add_weight(name=\"acc_denominator\", initializer='zeros')\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(tf.math.argmax(y_pred, -1), tf.int32)\n",
    "        y_true = tf.reshape(tf.cast(y_true, tf.int32), [-1])\n",
    "        self.acc_numerator.assign_add(tf.math.reduce_sum(tf.cast(y_pred == y_true, tf.float32)))\n",
    "        self.acc_denominator.assign_add(tf.cast(tf.shape(y_true)[0], tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.acc_numerator / self.acc_denominator\n",
    "        \n",
    "    def reset_states(self):\n",
    "        self.acc_numerator.assign(0.)\n",
    "        self.acc_denominator.assign(0.)\n",
    "        \n",
    "        \n",
    "def log_loss(y_true, y_pred):\n",
    "    log = lambda x : tf.math.log(tf.math.maximum(x, 1e-7)) # prevent log(0) causing nan\n",
    "    \n",
    "    classes_num, batch_size = tf.shape(y_pred)[1], tf.shape(y_pred)[0]\n",
    "    y_pred = tf.reshape(y_pred, [-1])  # [batch_size * n_class]\n",
    "    y_true = tf.reshape(tf.cast(y_true, tf.int32), [-1])\n",
    "    y_true_idx = tf.reshape(tf.range(0, batch_size) * classes_num + y_true, [-1])\n",
    "    loss = - log(tf.gather(y_pred, y_true_idx))\n",
    "    return loss\n",
    "\n",
    "def focal_loss(y_true, y_pred, alpha = [[1], [1], [1], [1], [1], [1], [1], [1], [1], [1]], epsilon = 1e-7, gamma=2.0):\n",
    "    log = lambda x : tf.math.log(tf.math.maximum(x, 1e-7)) # prevent log(0) causing nan\n",
    "    \n",
    "    # Each label has an alpha\n",
    "\n",
    "    classes_num, batch_size = tf.shape(y_pred)[1], tf.shape(y_pred)[0]\n",
    "    y_pred = tf.reshape(y_pred, [-1])  # [batch_size * n_class]\n",
    "    y_true = tf.reshape(tf.cast(y_true, tf.int32), [-1]) # [batch_size]\n",
    "    y_true_idx = tf.reshape(tf.range(0, batch_size) * classes_num + y_true, [-1])\n",
    "\n",
    "    y_prob = tf.gather(y_pred, y_true_idx)\n",
    "    \n",
    "    weight = tf.gather(tf.constant(alpha, tf.float32), y_true) * tf.pow(1. - y_prob, gamma)\n",
    "    \n",
    "    loss = weight * (- log(y_prob))\n",
    "    return loss\n",
    "\n",
    "#model.compile(optimizer=optimizers.Adam(1e-3), loss=log_loss, metrics=[multiclass_accuracy()])\n",
    "#model.fit(x_train, y_train, validation_split=0.2, epochs = 5)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-3), loss=focal_loss, metrics=[multiclass_accuracy()])\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
