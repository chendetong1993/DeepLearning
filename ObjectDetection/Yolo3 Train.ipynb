{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Yolo V3\n",
    "\n",
    "Here is an example of how to train a yolo v3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# A sample of Dataset Generator\n",
    "class DatasetGen(object):\n",
    "    def __init__(self):\n",
    "        self.imgs_cnt = 1\n",
    "        self.imgs_idx = 0\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.imgs_idx < self.imgs_cnt:\n",
    "            self.imgs_idx += 1\n",
    "            # read image from local\n",
    "            x = cv2.imread('./data/girl.png')\n",
    "            x = cv2.resize(x, (416, 416))\n",
    "            # bounding boxes [x1, y1, x2, y2, class]\n",
    "            y = np.array([\n",
    "                [0.18494931, 0.03049111, 0.9435849,  0.96302897, 0],\n",
    "                [0.22494931, 0.01949111, 0.3435849,  0.56302897, 2],\n",
    "                [0.01586703, 0.35938117, 0.01686703, 0.36938117, 56]])\n",
    "            return x, y\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test whether raw dataset can be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in DatasetGen():\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DatasetPre(object):\n",
    "    def __init__(self, \n",
    "                 img_size = 416, \n",
    "                 anchors = np.array([[(116, 90), (156, 198), (373, 326)],\n",
    "                                    [(30, 61), (62, 45),(59, 119)], \n",
    "                                     [(10, 13), (16, 30), (33, 23)]])):\n",
    "        self.img_size = img_size\n",
    "        self.anchors = anchors / img_size\n",
    "        self.anchors_info = np.array([[x, y, (self.img_size // 32) * (2 ** x)] \n",
    "                                         for x in range(anchors.shape[1]) \n",
    "                                         for y in range(anchors.shape[0])])\n",
    "        self.anchors_flat = self.anchors.reshape(-1, self.anchors.shape[-1])\n",
    "        \n",
    "    @staticmethod\n",
    "    def expand_repeat_axis(var, expand_axis, repat_cnt):\n",
    "        return np.expand_dims(var, expand_axis).repeat(repat_cnt, axis=expand_axis)\n",
    "                 \n",
    "    # Transform\n",
    "    def transform(self, x, y):\n",
    "        assert(x.shape == (self.img_size, self.img_size, 3))\n",
    "        new_x = x / 255\n",
    "\n",
    "        # calculate anchor index for true boxes\n",
    "        box_xy = (y[..., 2:4] + y[..., 0:2]) / 2\n",
    "        box_wh = y[..., 2:4] - y[..., 0:2]\n",
    "        anchor_area = self.anchors_flat[..., 0] * self.anchors_flat[..., 1]\n",
    "        box_area = box_wh[..., 0] * box_wh[..., 1]\n",
    "        box_wh_er = self.expand_repeat_axis(box_wh, 1, self.anchors_flat.shape[0])\n",
    "        intersection = np.minimum(box_wh_er[..., 0], self.anchors_flat[..., 0]) * \\\n",
    "                        np.minimum(box_wh_er[..., 1], self.anchors_flat[..., 1])\n",
    "        iou = intersection / (self.expand_repeat_axis(box_area, -1, self.anchors_flat.shape[0]) + anchor_area - intersection)\n",
    "        anchor_idxs = np.argmax(iou, axis=-1)\n",
    "\n",
    "        # new_y: list [(grid, grid, anchors, [x1, y1, x2, y2, obj, class])]\n",
    "        new_y = [np.zeros((grid_size, grid_size, self.anchors.shape[1], 6))\n",
    "                 for grid_size in np.unique(self.anchors_info[:,2])]\n",
    "        \n",
    "        for idx in range(anchor_idxs.shape[0]):\n",
    "            i, j, grid_size = self.anchors_info[anchor_idxs[idx]]\n",
    "            s_grid_xy = (box_xy[idx] // (1 / grid_size)).astype(np.uint8)\n",
    "            s_box_loc = y[..., 0:4][idx]\n",
    "            \"\"\"\n",
    "            s_box_xy = box_xy[idx] * grid_size - s_grid_xy\n",
    "            s_box_wh = np.log(box_wh[idx] / self.anchors[i, j])\n",
    "            \"\"\"\n",
    "            new_y[i][s_grid_xy[1], s_grid_xy[0], j] = [s_box_loc[0], s_box_loc[1], s_box_loc[2], s_box_loc[3], 1, y[idx, 4]]\n",
    "            #print(new_y[i][s_grid_xy[1], s_grid_xy[0], j])\n",
    "        return new_x, new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test whether dataset can be preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocess = DatasetPre()\n",
    "for x, y in DatasetGen():\n",
    "    new_x, new_y = dataset_preprocess.transform(x, y)\n",
    "    print(new_x.shape, [elem.shape for elem in new_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def yolo_boxes(pred):\n",
    "        # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))\n",
    "        grid_size = tf.shape(pred)[1]\n",
    "        box_xy, box_wh, objectness, class_probs = tf.split(pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "        box_xy = tf.sigmoid(box_xy)\n",
    "        objectness = tf.sigmoid(objectness)\n",
    "        class_probs = tf.sigmoid(class_probs)\n",
    "        pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\n",
    "\n",
    "        # !!! grid[x][y] == (y, x)\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
    "\n",
    "        box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.cast(grid_size, tf.float32)\n",
    "        box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "        box_x1y1 = box_xy - box_wh / 2\n",
    "        box_x2y2 = box_xy + box_wh / 2\n",
    "        bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "        return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "    def broadcast_iou(box_1, box_2):\n",
    "        # box_1: (..., (x1, y1, x2, y2))\n",
    "        # box_2: (N, (x1, y1, x2, y2))\n",
    "\n",
    "        # broadcast boxes\n",
    "        box_1 = tf.expand_dims(box_1, -2)\n",
    "        box_2 = tf.expand_dims(box_2, 0)\n",
    "        # new_shape: (..., N, (x1, y1, x2, y2))\n",
    "        new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n",
    "        box_1 = tf.broadcast_to(box_1, new_shape)\n",
    "        box_2 = tf.broadcast_to(box_2, new_shape)\n",
    "\n",
    "        int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) - tf.maximum(box_1[..., 0], box_2[..., 0]), 0)\n",
    "        int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) - tf.maximum(box_1[..., 1], box_2[..., 1]), 0)\n",
    "        int_area = int_w * int_h\n",
    "        box_1_area = (box_1[..., 2] - box_1[..., 0]) * (box_1[..., 3] - box_1[..., 1])\n",
    "        box_2_area = (box_2[..., 2] - box_2[..., 0]) * (box_2[..., 3] - box_2[..., 1])\n",
    "        return int_area / (box_1_area + box_2_area - int_area)\n",
    "\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        # 1. transform all pred outputs\n",
    "        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(y_pred)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "\n",
    "        # 2. transform all true outputs\n",
    "        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n",
    "        true_box, true_obj, true_class_idx = tf.split(y_true, (4, 1, 1), axis=-1)\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
    "\n",
    "        # give higher weights to small boxes\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - tf.cast(grid, tf.float32)\n",
    "        true_wh = tf.math.log(true_wh / anchors)\n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh), tf.zeros_like(true_wh), true_wh)\n",
    "\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        # ignore false positive when iou is over threshold\n",
    "        best_iou = tf.map_fn(\n",
    "            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(\n",
    "                x[1], tf.cast(x[2], tf.bool))), axis=-1),\n",
    "            (pred_box, true_box, obj_mask),\n",
    "            tf.float32)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        obj_loss = tf.keras.losses.binary_crossentropy(true_obj, pred_obj)\n",
    "        obj_loss = obj_mask * obj_loss + (1 - obj_mask) * ignore_mask * obj_loss\n",
    "        # TODO: use binary_crossentropy instead\n",
    "        class_loss = obj_mask * tf.keras.losses.sparse_categorical_crossentropy(true_class_idx, pred_class)\n",
    "\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    return yolo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "anchor_boxes = np.array([[(116, 90), (156, 198), (373, 326)], [(30, 61), (62, 45),(59, 119)],  [(10, 13), (16, 30), (33, 23)]])\n",
    "num_classes = 80\n",
    "loss = [YoloLoss(mask, classes=num_classes) for mask in anchor_boxes]\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "model = tf.keras.models.load_model('yolo3.h5')\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(verbose=1),\n",
    "    EarlyStopping(patience=3, verbose=1),\n",
    "    ModelCheckpoint('yolov3_train_{epoch}.tf',verbose=1, save_weights_only=True),\n",
    "    TensorBoard(log_dir='logs')\n",
    "]\n",
    "\n",
    "#train_dataset =  (np.zeros(1, 416, 416, 3), (np.zeros((1, 13, 13, 3, 6)), np.zeros((1, 26, 26, 3, 6)), np.zeros((1, 52, 52, 3, 6))))\n",
    "#validaion_data = (np.zeros(1, 416, 416, 3), (np.zeros((1, 13, 13, 3, 6)), np.zeros((1, 26, 26, 3, 6)), np.zeros((1, 52, 52, 3, 6))))\n",
    "history = model.fit(train_dataset, epochs=100, callbacks=callbacks, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
