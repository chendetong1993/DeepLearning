{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据输入 tf.data.Dataset.from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 28, 28) (512, 10)\n",
      "(512, 28, 28) (512, 10)\n",
      "(512, 28, 28) (512, 10)\n",
      "(464, 28, 28) (464, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "train_x = np.zeros((1000, 28, 28))\n",
    "train_y = np.zeros((1000, 10))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(20).repeat(2).batch(512)\n",
    "\n",
    "for x, y in dataset:\n",
    "    print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据输入 tf.TFRecordReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 64, 64) (512,)\n",
      "(488, 64, 64) (488,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tfrecord_filename = './train.tfrecord'\n",
    "\n",
    "class encode_and_write:\n",
    "    def __init__(self):\n",
    "        self.feature_dict = {\n",
    "            'ndarray' : self._ndarray_feature, \n",
    "            'bytes' : self._bytes_feature, \n",
    "            'float' : self._float_feature,\n",
    "            'double' : self._float_feature, \n",
    "            'bool' : self._int64_feature,\n",
    "            'enum' : self._int64_feature, \n",
    "            'int' : self._int64_feature,\n",
    "            'uint' : self._int64_feature\n",
    "        }\n",
    "    def _ndarray_feature(self, value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.tobytes()]))\n",
    "    \n",
    "    def _bytes_feature(self, value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def _float_feature(self, value):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "    def _int64_feature(self, value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    def _encode_example(self, example):\n",
    "        \"\"\"Creates a tf.Example message ready to be written to a file.\"\"\"\n",
    "        feature = {}\n",
    "        for vname in example:\n",
    "            vtype = type(example[vname]).__name__\n",
    "            feature[vname] = self.feature_dict[vtype](example[vname])\n",
    "        # Create a Features message using tf.train.Example.\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "\n",
    "    def run(self, filename, datasets):\n",
    "        with tf.io.TFRecordWriter(filename) as writer:\n",
    "            for vdata in datasets:\n",
    "                example = self._encode_example(vdata)\n",
    "                writer.write(example)\n",
    "  \n",
    "class datasets_stream:\n",
    "    def __iter__(self):\n",
    "        self.cnt = 1000\n",
    "        self.idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.idx < self.cnt:\n",
    "            self.idx += 1\n",
    "            return {\"image\": np.zeros((64, 64), np.uint8), \"label\": 0}\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "encode_and_write().run(tfrecord_filename, iter(datasets_stream()))\n",
    "\n",
    "class read_and_decode:\n",
    "    def __init__(self):\n",
    "        self.feature_description_dict = {\n",
    "            'ndarray' : self._bytes_feature_description, \n",
    "            'bytes' : self._bytes_feature_description, \n",
    "            'float' : self._float_feature_description,\n",
    "            'double' : self._float_feature_description, \n",
    "            'bool' : self._int64_feature_description,\n",
    "            'enum' : self._int64_feature_description, \n",
    "            'int' : self._int64_feature_description,\n",
    "            'uint' : self._int64_feature_description\n",
    "        }\n",
    "    \n",
    "    def _bytes_feature_description(self):\n",
    "        return tf.io.FixedLenFeature([], tf.string)\n",
    "\n",
    "    def _float_feature_description(self):\n",
    "        return tf.io.FixedLenFeature([], tf.float)\n",
    "\n",
    "    def _int64_feature_description(self):\n",
    "        return tf.io.FixedLenFeature([], tf.int64)\n",
    "    \n",
    "    def _decode_example(self, e, example):\n",
    "        res = []\n",
    "        for vname in example:\n",
    "            vtype = type(example[vname]).__name__\n",
    "            if vtype == \"ndarray\":\n",
    "                res.append(tf.reshape(tf.io.decode_raw(e[vname], {\n",
    "                    'float32' : tf.float32,\n",
    "                    'float64' : tf.float64,\n",
    "                    'int32' : tf.int32,\n",
    "                    'uint16' : tf.uint16,\n",
    "                    'uint8' : tf.uint8,\n",
    "                    'int16' : tf.int16,\n",
    "                    'int8' : tf.int8,\n",
    "                    'int64' : tf.int64\n",
    "                }[str(example[vname].dtype)]), example[vname].shape))\n",
    "            else:\n",
    "                res.append(tf.cast(e[vname], {\n",
    "                    'float' : tf.float32,\n",
    "                    'int' : tf.int32\n",
    "                }[vtype]))\n",
    "            \"\"\"\"\"\"\n",
    "        return res\n",
    "    \n",
    "    def run(self, filename, example):\n",
    "        reader = tf.data.TFRecordDataset(filename)\n",
    "        feature_description = {}\n",
    "        for vname in example:\n",
    "            vtype = type(example[vname]).__name__\n",
    "            feature_description[vname] = self.feature_description_dict[vtype]()\n",
    "        reader = reader.map(lambda e: tf.io.parse_single_example(e, feature_description))\n",
    "        reader = reader.map(lambda e: self._decode_example(e, example))\n",
    "        return reader\n",
    "\n",
    "#tfrecord_filename = tf.io.gfile.glob(os.path.join(ds_path, 'records/*.tfrec'))#records/train*.tfrec\n",
    "reader = read_and_decode().run(tfrecord_filename, {\"image\": np.zeros((64, 64), np.uint8), \"label\": 0})\n",
    "\n",
    "batch =  reader.shuffle(20).repeat(1).batch(512)\n",
    "for x, y in batch:\n",
    "    print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据输入 tf.data.Dataset.from_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 28, 28) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def our_generator():\n",
    "    for i in range(10):\n",
    "        x = np.random.rand(28,28)\n",
    "        y = np.random.randint(1,10, size=1)\n",
    "        yield x, y\n",
    "    \n",
    "    \n",
    "dataset = tf.data.Dataset.from_generator(our_generator, (tf.float32, tf.int16))\n",
    "batch =  dataset.shuffle(20).repeat(2).batch(512)\n",
    "for x, y in batch:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "#(10, 28, 28) (10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默认数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "train_x = np.zeros((1000, 28, 28, 1))\n",
    "train_y = np.zeros((1000, 10))\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "     featurewise_center=True,\n",
    "     featurewise_std_normalization=True,\n",
    "     rotation_range=20,\n",
    "     width_shift_range=0.2,\n",
    "     height_shift_range=0.2,\n",
    "     horizontal_flip=True)\n",
    " \n",
    "datagen.fit(train_x)\n",
    "batch = datagen.flow(train_x, train_y, batch_size=512)\n",
    "\n",
    "for x, y in batch:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 28, 28, 1) (512, 10)\n",
      "(512, 28, 28, 1) (512, 10)\n",
      "(512, 28, 28, 1) (512, 10)\n",
      "(464, 28, 28, 1) (464, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "train_x = np.zeros((1000, 28, 28, 1), dtype = np.float32)\n",
    "train_y = np.zeros((1000, 10), dtype = np.float32)\n",
    "\n",
    "def mixup(img_batch, label_batch):\n",
    "    batch_size = tf.shape(img_batch)[0]\n",
    "    weight = tf.random.uniform([batch_size])\n",
    "    x_weight = tf.reshape(weight, [batch_size, 1, 1, 1])\n",
    "    y_weight = tf.reshape(weight, [batch_size, 1])\n",
    "    index = tf.random.shuffle(tf.range(batch_size, dtype=tf.int32))\n",
    "    x1, x2 = img_batch, tf.gather(img_batch, index)\n",
    "    img_batch = x1 * x_weight + x2 * (1. - x_weight)\n",
    "    y1, y2 = label_batch, tf.gather(label_batch, index)\n",
    "    label_batch = y1 * y_weight + y2 * (1. - y_weight)\n",
    "    return img_batch, label_batch\n",
    "\n",
    "batch = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(20).repeat(2).batch(512)\n",
    "batch = batch.map(lambda a, b : mixup(a, b))\n",
    "\n",
    "\n",
    "for x, y in batch:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
