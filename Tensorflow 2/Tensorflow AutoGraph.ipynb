{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorFlow之前是静态图，即必须把所有的操作以及网络结构定义好，最后才执行，是分开的，后来有了动态图功能，即Eager Execution\n",
    "\n",
    "在TensorFlow 2.0中，默认情况下启用了急切执行。 对于用户而言直观且灵活（运行一次性操作更容易，更快），但这可能会牺牲性能和可部署性。\n",
    "要获得最佳性能并使模型可在任何地方部署，可以优先使用tf.function从程序中构建图。 因为有AutoGraph，可以使用tf.function构建高效性能的Python代码，但仍有一些陷阱需要警惕。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "print(add(tf.ones([2, 2]), tf.ones([2, 2])))\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    result = add(v, 1.0)\n",
    "print(tape.gradient(result, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 0.28980239999987134\n",
      "Function conv: 0.2602965999999469\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import tensorflow as tf\n",
    "\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "    return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "# warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33098197 0.488799095 0.288527369 0.0346468687 0.239103079]\n",
      "[0.319402844 0.453262776 0.280778825 0.0346330106 0.234648377]\n",
      "[0.308966845 0.424577296 0.273625731 0.0346191674 0.230434582]\n",
      "[0.299496889 0.400779516 0.266995341 0.0346053392 0.226440668]\n",
      "[0.290852129 0.380615741 0.260826766 0.0345915295 0.222648159]\n",
      "[0.2829189 0.36324206 0.25506866 0.0345777385 0.219040602]\n",
      "[0.275604397 0.348066479 0.2496773 0.0345639624 0.215603456]\n",
      "[0.268831939 0.334659696 0.244615257 0.0345502 0.212323636]\n",
      "[0.262537599 0.322701454 0.239850268 0.0345364586 0.209189519]\n",
      "[0.256667465 0.311947554 0.235354289 0.0345227271 0.206190571]\n",
      "[0.251175851 0.302207798 0.231102884 0.0345090143 0.203317374]\n",
      "[0.24602364 0.293331742 0.227074623 0.0344953202 0.200561345]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.24117719, 0.28519845, 0.22325058, 0.03448164, 0.19791473],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Simple loop\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "\n",
    "f(tf.random.uniform([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing for loop\n",
      "Tracing fizzbuzz branch\n",
      "Tracing fizz branch\n",
      "Tracing buzz branch\n",
      "Tracing default branch\n",
      "1\n",
      "2\n",
      "fizz\n",
      "4\n",
      "buzz\n",
      "1\n",
      "2\n",
      "fizz\n",
      "4\n",
      "buzz\n",
      "fizz\n",
      "7\n",
      "8\n",
      "fizz\n",
      "buzz\n",
      "11\n",
      "fizz\n",
      "13\n",
      "14\n",
      "fizzbuzz\n",
      "16\n",
      "17\n",
      "fizz\n",
      "19\n",
      "buzz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def fizzbuzz(n):\n",
    "  for i in tf.range(1, n + 1):\n",
    "    print('Tracing for loop')\n",
    "    if i % 15 == 0:\n",
    "      print('Tracing fizzbuzz branch')\n",
    "      tf.print('fizzbuzz')\n",
    "    elif i % 3 == 0:\n",
    "      print('Tracing fizz branch')\n",
    "      tf.print('fizz')\n",
    "    elif i % 5 == 0:\n",
    "      print('Tracing buzz branch')\n",
    "      tf.print('buzz')\n",
    "    else:\n",
    "      print('Tracing default branch')\n",
    "      tf.print(i)\n",
    "\n",
    "fizzbuzz(tf.constant(5))\n",
    "fizzbuzz(tf.constant(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
